<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>ProtE Workflow</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>







<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">ProtE Workflow</h1>



<p>All 4 functions streamline the following data processing:</p>
<ol style="list-style-type: decimal">
<li><p>Normalization of proteomic intensity values</p></li>
<li><p>Filtering based on the percentage of missing values.</p></li>
<li><p>Imputation of missing data to ensure robust downstream
analysis.</p></li>
<li><p>Description fetching for DIA-NN input files: .pg_matrix.tsv, and
ProteomeDiscoverer input files.</p></li>
</ol>
<div id="normalization" class="section level2">
<h2>Normalization</h2>
<p>Mass Spectrometry quantitative data produced by software tools such
as Proteome Discoverer and MaxQuant may be required to be processed with
Normalization methods to reduce their systemic bias. The ProtE package
offers different methods of normalization that are provided via the
normalization argument. These options include a simple log2
transformation of the data, Cyclic Loess normalization that aims to
reduce their dissimilarities , and Quantile normalization which is
implemented to make the distribution of each feature identical. Both
Quantile and Cyclic loess Normalization are applied to the log2
transformed data and are implemented using functions of the limma
package. The data can also be transformed with median normalization, in
which all intensity values are divided by each sample’s median
intensity, resulting in a median equal to 1 across the protein data set
. Other normalization methods share an initial step of dividing each
intensity value by the total sum of intensities for its respective
sample. Total Ion Current normalization then rescales the values by
multiplying them by the average Total Ion Current while Parts Per
Million (PPM) normalization scales the values by multiplying them by one
million. Lastly, Variable Stabilizing Normalization is also available
implementing the corresponding function of the vsn package . Because the
data output from DIA-NN has already been normalized with the MaxLFQ
quantification, extra normalizing methods are suggested to be selected
cautiously.</p>
</div>
<div id="filtering-of-missing-values" class="section level2">
<h2>Filtering of Missing Values</h2>
<p>When working with mass spectrometry-based proteomics data, a common
issue encountered is the presence of missing values in the intensity
measurements for each protein. These missing values can occur for
several reasons. Some proteins may not be identified in the sample due
to technical limitations, their abundances may fall below the detection
limit of the analyzing instrument, or the proteins may be completely
absent from the examined sample. ProtE offers the option of filtering
Proteins based on the percentage of missing values they contain.
Specifically, functions include the argument filtering_value, which
refers to the percentage of missing values per protein allowed to remain
in the filtered dataset. Thus, if the user sets it to 100, no filtering
will occur, and the proteins will not be altered.<br />
The parameter global_filtering determines if filtering for missing
values will be performed across all groups or separately inside each
group. When the intensity values of a protein contain only missing
values, they will be always omitted from the analysis. Also, the reverse
positive proteins (REV) will be excluded, when the input is the
ProteinGroups.txt from MaxQuant.</p>
</div>
<div id="imputation" class="section level2">
<h2>Imputation</h2>
<p>The ProtE package also offers a few options for estimating the
missing values, via the argument imputation of each function. The
available imputation methods include simply assigning the limit of
detection of the experiment (lowest abundance value in the dataset), or
its half to the missing values or values derived from the Gaussian
distribution of it. Other options include treating missing values as
zeros or assigning the mean abundance of each protein to its missing
values. Additionally, k-nearest neighbors (kNN) imputation is available
from the package VIM and missRanger, a quicker multivariate imputation
algorithm alternative to missForest (based on random forests), from the
package of the same name.</p>
</div>
<div id="description-fetching" class="section level2">
<h2>Description fetching</h2>
<p>The input file <code>.pg_matrix.tsv</code> from DIA-NN does not
provide descriptive information for each Protein ID. To address this
issue, the function <code>dianno</code> includes an argument called
<code>description</code>, which allows for the retrieval of descriptive
information such as gene names, organisms, and more. This option is also
available for Proteome Discoverer inputs that lack this information.
Detailed data is obtained from the UniProt database, using the
UniProt.ws package. The Description information will be shown in each
Excel file created that contains the dataset.</p>
</div>
<div id="statistical-analysis" class="section level2">
<h2>Statistical Analysis</h2>
<p>Statistical analysis will then be performed, including pairwise
comparisons between the groups. The parameter <code>independent</code>
allows users to specify whether the group variables should be analyzed
as independent (e.g. control samples vs patient samples) or as matched
pairs (e.g. same patients before and after treatment) By default, it is
set to <code>independent = TRUE</code> , and to run a paired/matched
test <code>independent = FALSE</code>, the user must provide groups with
the same number of samples, with the order of the samples across them
remaining the same.</p>
<p>The output includes an Excel file,
<code>Statistical_analysis.xlsx</code>, which provides detailed
information for each protein, including the average abundance, standard
deviation, ratio, and log2 fold change of values between groups. It also
includes the p-values and Benjamini–Hochberg adjusted p-values from
pairwise Mann-Whitney comparisons, as well as Kruskal-Wallis test
results when the number of groups is greater than 2. Additionally, the
file contains in the columns “Bartlett_p” and “Levene_p” the p_values
for the reported statistical tests, that examine the homoscedasticity of
each proteins’ abundances. Last but not least, the pValue and the
pseudoF value from the multivariate PERMANOVA statistical test,
utilizing the function adonis2 from the package vegan.</p>
<p>Another Excel file, <code>limma_statistics.xlsx</code>, contains
results from the parametric <code>limma</code> statistical test. For the
limma statistics the dataset has been fit to a linear model and then
moderated by empirical Bayes method. This includes the ANOVA F-value,
p-value, and adjusted p-value, as well as the B-statistic, unadjusted
p-value, and Benjamini–Hochberg adjusted p-value for pairwise t-test
comparisons between groups, as well as the ANOVA F-value, p-value, and
adjusted p-value when the number of groups is greater than 2.</p>
</div>
<div id="data-visualization" class="section level2">
<h2>Data visualization</h2>
<p>To visualize the distribution of data for each sample, a boxplot and
violin plot are generated using the ggplot2 package. All protein
abundance values are transformed via log2 transformation to ensure
normality and comparability across samples. Sample names are displayed
on the plots; however, if the names are too lengthy, only their last 25
characters will appear. To improve readability, it is recommended to use
shorter sample names when possible. Additionally, the samples are
colored according to their respective groups.</p>
<p>Principal Component Analysis (PCA) is also performed on the
log2-transformed protein abundance data for each sample. The data are
scaled and centered prior to the analysis. A PCA plot is created,
displaying the samples in a two-dimensional space where the axes
represent the first two principal components.</p>
<p>An additional PCA plot is created using only the significant proteins
identified during the statistical analysis. For pairwise comparisons
between two groups, significant proteins are selected based on their
statistical results from the comparison. When analyzing more than two
groups, significant proteins are identified using analysis of variance
(ANOVA) across all groups.</p>
<p>Users can select the statistical method for determining significance
by setting the <code>parametric</code> parameter. Setting
<code>parametric = TRUE</code> uses results from the limma t-test or
ANOVA, while <code>parametric = FALSE</code> uses results from the
Mann-Whitney U test or Kruskal-Wallis test. The user can further specify
the significance threshold with the <code>significance</code> parameter:
setting <code>significance = &quot;p&quot;</code> uses a raw p-value threshold of
0.05, and <code>significance = &quot;BH&quot;</code> uses the Benjamini-Hochberg
adjusted p-value threshold.</p>
<p>A PCA plot is then generated based on the significant proteins.</p>
<p>Additionally, a heatmap of the significant proteins is generated
using the ComplexHeatmap package. Proteins are clustered based on
euclidean distance in abundance patterns across groups, and the heatmap
provides an overview of group-specific differences.</p>
<p>Lastly, an excel file names Quality_check.xlsx provides information
about the percentage of missing values before and after filtering, along
with the scores of the first 2 principal components for each sample.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
